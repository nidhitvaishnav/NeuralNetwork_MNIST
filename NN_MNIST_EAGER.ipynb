{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nidhi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8ad4aa567d7d>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\nidhi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\nidhi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\nidhi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\nidhi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\nidhi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_hidden = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_cnn0 = tf.layers.Conv2D(32, 5, activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_pool2x2 = tf.layers.MaxPooling2D(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_cnn1 = tf.layers.Conv2D(64, 5, padding=\"same\", activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_pool3x3 = tf.layers.MaxPooling2D(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_cnn2 = tf.layers.Conv2D(64, 5,  padding=\"same\", activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_pool4x4 = tf.layers.MaxPooling2D(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_cnn3 = tf.layers.Conv2D(64, 5,  padding=\"same\", activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flatten = tf.layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc0 = tf.layers.Dense(dim_hidden, activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dropout = tf.layers.Dropout(rate=0.80) # dropout rate is 0.75. Retain 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = tf.layers.Dense(10, activation = tf.nn.relu) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation\n",
    "def prediction(X, training):\n",
    "    values = tf.constant(X)\n",
    "    values = layer_pool4x4(values) # this must be the first layer\n",
    "    values = layer_cnn0(values)\n",
    "    values = layer_cnn1(values)\n",
    "    values = layer_cnn2(values)\n",
    "    values = layer_cnn3(values)\n",
    "    values = layer_pool3x3(values)\n",
    "    values = layer_flatten(values)\n",
    "    values = layer_fc0(values)\n",
    "    values = layer_dropout(values, training=training)\n",
    "    values = layer_fc1(values)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss\n",
    "def loss(X, y, training):\n",
    "    logits = prediction(X, training)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = logits)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(X, y):\n",
    "    logits = prediction(X, training = False)\n",
    "    predict = tf.argmax(logits, 1).numpy()\n",
    "    target = np.argmax(y, 1)\n",
    "    binary_accuracy = np.sum(predict == target)/len(target)\n",
    "    return(binary_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = mnist.validation.images\n",
    "y_validation = mnist.validation.labels\n",
    "X_validation = X_validation.reshape([-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_binary_accuracy() :\n",
    "    return(binary_accuracy(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 1e-3, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "iters = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, batch accuracy 0.220;  validation accuracy 0.148\n",
      "batch 100, batch accuracy 0.480;  validation accuracy 0.420\n",
      "batch 200, batch accuracy 0.620;  validation accuracy 0.662\n",
      "batch 300, batch accuracy 0.960;  validation accuracy 0.779\n",
      "batch 400, batch accuracy 0.820;  validation accuracy 0.799\n",
      "batch 500, batch accuracy 0.840;  validation accuracy 0.797\n",
      "batch 600, batch accuracy 0.900;  validation accuracy 0.803\n",
      "batch 700, batch accuracy 0.920;  validation accuracy 0.874\n",
      "batch 800, batch accuracy 0.860;  validation accuracy 0.881\n",
      "batch 900, batch accuracy 0.940;  validation accuracy 0.883\n",
      "batch 1000, batch accuracy 0.800;  validation accuracy 0.893\n",
      "batch 1100, batch accuracy 0.940;  validation accuracy 0.897\n",
      "batch 1200, batch accuracy 0.920;  validation accuracy 0.889\n",
      "batch 1300, batch accuracy 0.940;  validation accuracy 0.898\n",
      "batch 1400, batch accuracy 0.920;  validation accuracy 0.902\n",
      "batch 1500, batch accuracy 0.920;  validation accuracy 0.901\n",
      "batch 1600, batch accuracy 0.840;  validation accuracy 0.904\n",
      "batch 1700, batch accuracy 0.920;  validation accuracy 0.899\n",
      "batch 1800, batch accuracy 0.940;  validation accuracy 0.898\n",
      "batch 1900, batch accuracy 0.860;  validation accuracy 0.907\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters):\n",
    "    X, y = mnist.train.next_batch(batch_size)\n",
    "    X = X.reshape([-1,28,28,1])\n",
    "    optimizer.minimize(lambda: loss(X, y, True))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        batch_accuracy = binary_accuracy(X, y)\n",
    "        validation_accuracy = v_binary_accuracy()\n",
    "        print(\"batch %d, batch accuracy %.3f;  validation accuracy %.3f\" %\n",
    "                                (i, batch_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.8864\n"
     ]
    }
   ],
   "source": [
    "# evaluate the result\n",
    "X, y = mnist.test.images, mnist.test.labels\n",
    "X = X.reshape([-1,28,28,1])\n",
    "test_accuracy = binary_accuracy(X, y)\n",
    "print(\"test accuracy %g\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
